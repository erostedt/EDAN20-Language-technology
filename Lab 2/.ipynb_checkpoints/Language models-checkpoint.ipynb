{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns scanner objects that can be used to extract position information\n",
    "def tokenize(text, regex=re.compile('[\\p{L}<>/]+')):\n",
    "    return re.finditer(regex, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructs a dictionary with words as keys and character offset from beginning of document as values.\n",
    "def text_to_idx(tokens):\n",
    "    ddict = defaultdict(list)\n",
    "    for token in tokens:\n",
    "        ddict[token.group()].append(token.start())\n",
    "    return ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_file('./Selma.txt')\n",
    "tokens = tokenize(text)\n",
    "idx = text_to_idx(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern(text, pattern=r'([\\.\\?\\!])\\s+\\p{Lu}'):\n",
    "    regex = re.compile(pattern)\n",
    "    return re.finditer(regex, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text, regex=re.compile('[\\p{L}<>/]+')):\n",
    "    return re.findall(regex, text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: . D Start: 29\n",
      "Group: ! H Start: 45\n"
     ]
    }
   ],
   "source": [
    "s = 'Hej jag heter inte inte Göran. Du luktar bajs! Hatar alla?'\n",
    "for occurence in find_pattern(s):\n",
    "    print('Group:', occurence.group(), 'Start:', occurence.start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text, name='Selma_normalized.txt'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    sentence_idxs = find_pattern(text)\n",
    "    text = text.lower()\n",
    "    with open(name, 'w') as f:\n",
    "        start = 0\n",
    "        for idx in sentence_idxs:\n",
    "            end = idx.start()\n",
    "            sentence = text[start: end]\n",
    "            f.write('<s> ' + sentence.strip() + ' </s>\\n')\n",
    "            start = end + 2\n",
    "        f.write('<s> ' + text[start:].strip()[:-1] + ' </s>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(words, n):\n",
    "    num_words = len(words)\n",
    "    ngrams = [tuple(words[i: i + n]) for i in range(num_words - n + 1)]\n",
    "    ngrams_dict = defaultdict(int)\n",
    "    for ngram in ngrams:\n",
    "        ngrams_dict[ngram] += 1\n",
    "    return ngrams_dict, len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_normalized = read_file('./Selma_normalized.txt')\n",
    "freq_unigrams, num_unigrams = get_ngrams(get_words(text_normalized), 1)\n",
    "freq_bigrams, num_bigrams = get_ngrams(get_words(text_normalized), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info(words, freq_unigrams, freq_bigrams):\n",
    "    mi = {}\n",
    "    num_words = len(words)\n",
    "    factor = num_words ** 2 / (num_words - 1)\n",
    "    for bigram in freq_bigrams:\n",
    "        math.log(factor * freq_bigrams[bigram] / (freq_unigrams[bigram[0]] * freq_unigrams[bigram[1]]), 2)\n",
    "        \n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_unigram(sentence, freq_unigrams, num_unigrams):\n",
    "    prob_unigrams = {k: v / num_unigrams for k, v in freq_unigrams.items()}\n",
    "    sentence = sentence.strip().split(' ')\n",
    "    prob_sentence = 1\n",
    "    \n",
    "    print('========================================')\n",
    "    print('wi        C(wi)       #words       P(wi)')\n",
    "    print('========================================')\n",
    "    \n",
    "    for word in sentence:\n",
    "        prob_sentence *= prob_unigrams[(word, )]\n",
    "        print(word + '     ' + str(freq_unigrams[(word, )]) + '     ' + str(num_unigrams) + '       ' + str(prob_unigrams[(word, )]))\n",
    "    \n",
    "    \n",
    "    words_in_sentence = len(sentence)\n",
    "    entropy = -math.log(prob_sentence, 2) / words_in_sentence\n",
    "    \n",
    "    print('========================================')\n",
    "    print('Prob. Sentence:', prob_sentence)\n",
    "    print('Geo. Mean:', prob_sentence ** (1 / words_in_sentence))\n",
    "    print('Entropy rate:', entropy)\n",
    "    print('Perplexity:', 2 ** entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "wi        C(wi)       #words       P(wi)\n",
      "========================================\n",
      "det     21108     1013386       0.02082918058864046\n",
      "var     12090     1013386       0.01193030099093534\n",
      "en     13514     1013386       0.013335491115922265\n",
      "gång     1332     1013386       0.0013144053697209158\n",
      "en     13514     1013386       0.013335491115922265\n",
      "katt     16     1013386       1.578865308974073e-05\n",
      "som     16288     1013386       0.016072848845356064\n",
      "hette     97     1013386       9.571870935655317e-05\n",
      "nils     87     1013386       8.585080117546522e-05\n",
      "</s>     44950     1013386       0.04435624727399037\n",
      "========================================\n",
      "Prob. Sentence: 5.372851840063785e-27\n",
      "Geo. Mean: 0.002360589583951157\n",
      "Entropy rate: 8.726637050663335\n",
      "Perplexity: 423.62298249499145\n"
     ]
    }
   ],
   "source": [
    "sent = 'det var en gång en katt som hette nils </s>'\n",
    "tabulate_unigram(sent, freq_unigrams, num_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_bigram(sentence, freq_bigrams, num_bigrams, freq_unigrams, prob_unigrams):\n",
    "    sentence = sentence.strip().split(' ')\n",
    "    prob_sentence = 1\n",
    "    \n",
    "    print('========================================')\n",
    "    print('wi   wi+i   Ci,i+1    C(i)   P(wi+1|wi)')\n",
    "    print('========================================')\n",
    "    \n",
    "    words_in_sentence = len(sentence)\n",
    "    \n",
    "    for i in range(words_in_sentence - 1):\n",
    "        conditional_prob = freq_bigrams[(sentence[i], sentence[i+1])] / freq_unigrams[(sentence[i], )]\n",
    "        \n",
    "        _string = sentence[i] + '  ' + sentence[i+1] + '  ' + str(freq_bigrams[(sentence[i], sentence[i+1])]) \\\n",
    "              + '  ' + str(freq_unigrams[(sentence[i], )])\n",
    "        \n",
    "        if conditional_prob:\n",
    "            prob_sentence *= conditional_prob\n",
    "            _string += '  ' + str(conditional_prob)\n",
    "            \n",
    "        else:\n",
    "            prob_sentence *= prob_unigrams[(sentence[i+1], )]\n",
    "            _string += '  ' + '*Backoff  ' + str(prob_unigrams[(sentence[i+1], )])\n",
    "            \n",
    "        print(_string)\n",
    "    \n",
    "    \n",
    "    entropy = -math.log(prob_sentence, 2) / words_in_sentence\n",
    "    \n",
    "    print('========================================')\n",
    "    print('Prob. Sentence:', prob_sentence)\n",
    "    print('Geo. Mean:', prob_sentence ** (1 / words_in_sentence))\n",
    "    print('Entropy rate:', entropy)\n",
    "    print('Perplexity:', 2 ** entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "wi   wi+i   Ci,i+1    C(i)   P(wi+1|wi)\n",
      "========================================\n",
      "<s>  det  4175  44950  0.092880978865406\n",
      "det  var  3839  21108  0.1818741709304529\n",
      "var  en  712  12090  0.058891645988420185\n",
      "en  gång  706  13514  0.052242119283705785\n",
      "gång  en  20  1332  0.015015015015015015\n",
      "en  katt  6  13514  0.0004439840165754033\n",
      "katt  som  2  16  0.125\n",
      "som  hette  45  16288  0.002762770137524558\n",
      "hette  nils  0  97  *Backoff  8.585080117546522e-05\n",
      "nils  </s>  1  87  0.011494252873563218\n",
      "========================================\n",
      "Prob. Sentence: 1.1807154935570306e-19\n",
      "Geo. Mean: 0.0190233033325651\n",
      "Entropy rate: 5.716088402687074\n",
      "Perplexity: 52.56710585527739\n"
     ]
    }
   ],
   "source": [
    "sent2 = '<s> det var en gång en katt som hette nils </s>'\n",
    "prob_unigrams = {k: v / num_unigrams for k, v in freq_unigrams.items()}\n",
    "tabulate_bigram(sent2, freq_bigrams, num_bigrams, freq_unigrams, prob_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4e-06'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:.1e}'.format(0.0000024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
